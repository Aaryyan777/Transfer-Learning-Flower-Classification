import matplotlib.pyplot as plt
import numpy as np

# Data extracted from my training log
# Stage 1 Data
history_s1 = {
    'accuracy': [0.4527, 0.7370, 0.7791, 0.7975, 0.8208, 0.8462, 0.8553, 0.8678, 0.8750, 0.8792, 0.8971, 0.8968, 0.8961, 0.9137, 0.9111, 0.9159, 0.9215, 0.9276],
    'loss': [0.2489, 0.0947, 0.0770, 0.0671, 0.0575, 0.0479, 0.0444, 0.0400, 0.0375, 0.0367, 0.0322, 0.0306, 0.0312, 0.0265, 0.0251, 0.0243, 0.0224, 0.0208],
    'val_accuracy': [0.7337, 0.7674, 0.7686, 0.8093, 0.8442, 0.8256, 0.8512, 0.8523, 0.8779, 0.8419, 0.8872, 0.8651, 0.8814, 0.8616, 0.8709, 0.8814, 0.8826, 0.8814],
    'val_loss': [0.1218, 0.0951, 0.0815, 0.0772, 0.0639, 0.0608, 0.0541, 0.0581, 0.0465, 0.0512, 0.0428, 0.0452, 0.0464, 0.0528, 0.0472, 0.0453, 0.0468, 0.0454]
}

# Stage 2 Data
history_s2 = {
    'accuracy': [0.8866, 0.8898, 0.9060, 0.8918, 0.8999, 0.8968, 0.8924, 0.9117, 0.9101, 0.9105, 0.9097, 0.9044, 0.9107, 0.9160, 0.9156, 0.9149, 0.9152, 0.9197, 0.9216, 0.9130, 0.9152, 0.9272, 0.9227, 0.9241, 0.9259, 0.9212, 0.9207, 0.9231, 0.9301, 0.9320, 0.9252, 0.9363, 0.9411, 0.9402, 0.9378, 0.9375, 0.9375, 0.9367, 0.9329, 0.9401, 0.9395, 0.9336, 0.9371, 0.9402, 0.9458, 0.9390, 0.9499, 0.9337, 0.9561, 0.9427, 0.9344, 0.9439, 0.9304, 0.9441, 0.9298, 0.9493],
    'loss': [0.0349, 0.0331, 0.0289, 0.0334, 0.0314, 0.0311, 0.0308, 0.0280, 0.0274, 0.0293, 0.0278, 0.0278, 0.0266, 0.0254, 0.0258, 0.0241, 0.0243, 0.0214, 0.0239, 0.0275, 0.0257, 0.0223, 0.0209, 0.0215, 0.0214, 0.0214, 0.0227, 0.0228, 0.0214, 0.0203, 0.0202, 0.0191, 0.0189, 0.0178, 0.0184, 0.0178, 0.0176, 0.0197, 0.0185, 0.0170, 0.0181, 0.0175, 0.0173, 0.0162, 0.0162, 0.0160, 0.0144, 0.0197, 0.0144, 0.0181, 0.0177, 0.0162, 0.0176, 0.0161, 0.0184, 0.0167],
    'val_accuracy': [0.8756, 0.8849, 0.8895, 0.8942, 0.8953, 0.8988, 0.9058, 0.9047, 0.9093, 0.9093, 0.9105, 0.9105, 0.9140, 0.9151, 0.9128, 0.9105, 0.9116, 0.9105, 0.9105, 0.9070, 0.9070, 0.9081, 0.9058, 0.9058, 0.9058, 0.9081, 0.9105, 0.9105, 0.9105, 0.9105, 0.9116, 0.9116, 0.9116, 0.9140, 0.9140, 0.9116, 0.9116, 0.9140, 0.9128, 0.9105, 0.9128, 0.9151, 0.9151, 0.9163, 0.9163, 0.9163, 0.9163, 0.9163, 0.9174, 0.9163, 0.9163, 0.9163, 0.9163, 0.9174, 0.9174, 0.9163],
    'val_loss': [0.0389, 0.0367, 0.0353, 0.0341, 0.0333, 0.0330, 0.0327, 0.0323, 0.0319, 0.0316, 0.0314, 0.0313, 0.0312, 0.0311, 0.0311, 0.0310, 0.0309, 0.0309, 0.0309, 0.0308, 0.0307, 0.0306, 0.0305, 0.0304, 0.0304, 0.0304, 0.0303, 0.0303, 0.0303, 0.0303, 0.0302, 0.0302, 0.0302, 0.0302, 0.0301, 0.0302, 0.0303, 0.0302, 0.0302, 0.0302, 0.0302, 0.0301, 0.0301, 0.0301, 0.0301, 0.0301, 0.0301, 0.0301, 0.0301, 0.0301, 0.0301, 0.0301, 0.0301, 0.0301, 0.0301, 0.0301]
}

# Plotting function
def plot_learning_curves(history, title_prefix=""):
    epochs = range(1, len(history['accuracy']) + 1)

    plt.figure(figsize=(12, 5))

    # Plot Accuracy
    plt.subplot(1, 2, 1)
    plt.plot(epochs, history['accuracy'], 'b', label='Training accuracy')
    plt.plot(epochs, history['val_accuracy'], 'r', label='Validation accuracy')
    plt.title(f'{title_prefix} Training and Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True)

    # Plot Loss
    plt.subplot(1, 2, 2)
    plt.plot(epochs, history['loss'], 'b', label='Training loss')
    plt.plot(epochs, history['val_loss'], 'r', label='Validation loss')
    plt.title(f'{title_prefix} Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.show()

# Plot for Stage 1
plot_learning_curves(history_s1, title_prefix="Stage 1 (128x128)")

# Plot for Stage 2
plot_learning_curves(history_s2, title_prefix="Stage 2 (150x150)")
